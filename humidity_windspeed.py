# -*- coding: utf-8 -*-
"""humidity_windspeed.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K25PrRpgtO8YoSpQqAttpQ2j96eoNptJ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing
import tensorflow as tf
import statsmodels as st
from statsmodels.tsa.holtwinters import SimpleExpSmoothing
#from statsmodels.tsa.seasonal import STL
from sklearn.model_selection import train_test_split

"""# SUMMARY
With the LSTM model, we want to predict the temperature and wind_speed just the day before the expedition (we will be able to predict temperature, humidity rate and wind speed for the next 20 hours).

We took the dataset from the South Est zone of France that contains the French Alpes, for the year 2017. 

This is useful for checking the conditions one day before the expedition. 

To check if it is good conditions or not, we will put some simple thresholds (min and max thresholds). 
"""

!pip install git+https://github.com/statsmodels/statsmodels.git

"""### Usefull function """

# Normalize the dataset to have more robust predictions 
def normalize(dataset):
  dataNorm=((dataset-dataset.min())/(dataset.max()-dataset.min()))
  return dataNorm

def temp_int(longeur):
    return list(range(-longeur, 0))

"""# Dataset """

from google.colab import drive
drive.mount('/content/drive/')

import pandas as pd
df2017 = pd.read_csv('/content/drive/My Drive/DL_project/data/ground_stations/SE2017.csv')

df2017

"""### Choose 2 stations to train and make predictions """

num_station = 84107002	
num_test_station = 84150001
num_test_station = 84087001

# Allow to create dataset according to the station we choose thanks to the number of the station.
def index(station):
    data = df2017[(df2017['number_sta'] == station)]
    data['date'] = pd.to_datetime(data['date'], format='%Y%m%d %H:%M')
    data.set_index('date', inplace=True)
    # interpolate helps to fill the missing values 
    # Precipitation during the reporting period
    data['precip'] = data['precip'].interpolate('linear')
    #Humidity
    data['hu'] = data['hu'].interpolate('linear')
    #Wind speed 
    data['ff'] = data['ff'].interpolate('linear')
    data = data.drop(['number_sta', 'lat', 'lon', 'height_sta','psl'], axis = 1)
    return data

# Normalize the dataset to have more robust predictions 
def normalize(dataset, param):
  norm =((dataset[param]-dataset[param].min())/(dataset[param].max()-dataset[param].min()))
  return norm

def denormalize(array,orginal_dataset, param):
  array_original = np.array(orginal_dataset[param])
  denorm =(array*(np.nanmax(array_original)-np.nanmin(array_original)))+(np.nanmin(array_original))
  return denorm

def segment(dataset, intervale, futur):
    data = []
    labels = []
    for i in range(len(dataset)):
        debut_index = i
        fin_index = i + intervale
        futur_index = i + intervale + futur
        if futur_index >= len(dataset):
            break
        #data.append(dataset[variable][i:fin_index])
        data.append(dataset[i:fin_index])
        #labels.append(dataset[variable][fin_index:futur_index])
        labels.append(dataset[fin_index:futur_index])
    return np.array(data), np.array(labels)

#prepare bag of dataset according to the selection and print dim of dataset 
def segmentation(dataset,parametre):
    X, Y = segment(dataset, parametre, intervale = point_hist, futur = point_predis)
    #print(X)
    X = X.reshape(X.shape[0], point_hist,1)
    Y = Y.reshape(Y.shape[0], point_predis,1)
    print("Dimension du Passé: ", X.shape)
    print("Dimension du Futur: ", Y.shape)
    return X,Y

#prepare bag of dataset according to the selection and print dim of dataset 
def segmentation(dataset):
    X, Y = segment(dataset, intervale = point_hist, futur = point_predis)
    #print(X)
    X = X.reshape(X.shape[0], point_hist,1)
    Y = Y.reshape(Y.shape[0], point_predis,1)
    print("Dimension du Passé: ", X.shape)
    print("Dimension du Futur: ", Y.shape)
    return X,Y

"""## For Humidity

#### Creation of dataset
"""

#creation of data 
meteo_not_norm=index(num_station)
meteo_test_not_norm=index(num_test_station)

#normalize dataset
# FOR HUMIDITY 
meteo = normalize(meteo_not_norm,'hu')
meteo_test = normalize(meteo_test_not_norm,'hu')

# we take the average on periods of 120 measures =  2hours  
# transform to 12 periods of 2hours 
meteo_cp = meteo.resample('120T').mean()
meteo_test_cp = meteo_test.resample('120T').mean()

# We assume constant val if we don't have any information
meteo_cp = meteo_cp.fillna(method='bfill')
meteo_test_cp = meteo_test_cp.fillna(method='bfill')

meteo_cp
#meteo_test_cp

#Selection of the number of point to input and the number to predict
# from previous hours (140 hours because between 2 points = 2 hours)
point_hist = 70
# predict 10 next hours (20 next hours)
point_predis = 10

# For humidity

X_entrainement_hu,Y_entrainement_hu = segmentation(meteo_cp)

X_test_hu,Y_test_hu = segmentation(meteo_test_cp)

#epoch
EPOCH= 100

#modèle du réseaux de neurones(4 rangées (100,100,50,50) dont la première LSTM)
modele_lstm_hum = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(point_hist, input_shape=X_entrainement_hu.shape[-2:]),
    tf.keras.layers.Dense(100),
    tf.keras.layers.Dense(50),
    tf.keras.layers.Dense(point_predis)
    ])

modele_lstm_hum.summary()

#Comple with mse 
modele_lstm_hum.compile(optimizer='adam', metrics=['mae'], loss='mse')

#train 
history_hum = modele_lstm_hum.fit(X_entrainement_hu, Y_entrainement_hu, epochs=EPOCH, verbose = 0)

#predict with the station test 
YPred_hum = modele_lstm_hum.predict(X_test_hu, verbose=0)

# Evaluate the model on training set:
score = modele_lstm_hum.evaluate(X_entrainement_hu, Y_entrainement_hu, verbose=0)
print(' Train loss:', score[0])

# Evaluate the model on validation set:
score = modele_lstm_hum.evaluate(X_test_hu, Y_test_hu, verbose=0)
print(' Validation loss:', score[0])

import matplotlib.pyplot as plt
fig, ax = plt.subplots()
epoch = range(100)
ax.plot(epoch,history_hum.history['loss'],'o-',label="loss")
ax.set_xlabel("Epochs")
ax.set_ylabel("Cross_entropy loss")
ax.legend()
ax.set_title('Loss plot for epoch iteration')
plt.savefig("Loss_Train")

"""## Display the result """

Y_test_hum = Y_test_hu.reshape(Y_test_hu.shape[0], point_predis,)

def denormalize(array,orginal_dataset, param):
  array_original = np.array(orginal_dataset[param])
  denorm =(array*(np.nanmax(array_original)-np.nanmin(array_original)))+(np.nanmin(array_original))
  return denorm 

#Lists that contains values of prediction 
final_list_hu = []
Val_list_hu = []
meteo_test_not_norm = index(num_test_station)
# Among all the points predicted we take only one 

###  Prediction Y_pred from X_test 
for preds in YPred_hum:
    final_list_hu.append(preds[0])
train_np_array_hu = np.array(final_list_hu)
train_val_hu = denormalize(train_np_array_hu, meteo_test_not_norm, 'hu')



### True Y_test from X_test (Y_true) 
for preds in Y_test_hum:
    Val_list_hu.append(preds[0])   
test_np_array_hu = np.array(Val_list_hu)
test_val_hu = denormalize(test_np_array_hu,meteo_test_not_norm,'hu')

print(train_val_hu.shape)
print(test_val_hu.shape)

#Première figure: La prédiction comparé au réel sur les 3 ans avec 
plt.figure(figsize=(30,5))
sns.set(rc={"lines.linewidth": 3})
sns.lineplot(x=np.arange(train_val_hu[:300].shape[0]), y=train_val_hu[:300], color="green")
sns.set(rc={"lines.linewidth": 3})
sns.lineplot(x=np.arange(test_val_hu[:300].shape[0]), y=test_val_hu[:300], color="coral")
plt.margins(x=0, y=0.5)
plt.xlabel('Time')
plt.ylabel('Humidity(%)')
plt.ylim(0,110)
plt.legend(["Original", "Prédiction"])

def plot_multi_etape_hu(historique, vrai_futur, prediction):
    plt.figure(figsize=(12, 6))
    num_passe = temp_int(len(historique))
    num_futur = len(vrai_futur)
    plt.plot(num_passe, np.array(historique[:, 0]), label='given passed')
    plt.plot(np.arange(num_futur), np.array(vrai_futur), label='True future')
    plt.fill_between(range(-70,10), 20, 75, color='C0', alpha = 0.3, label = "Good humidity conditions")
    plt.title('Prediction of humidity rate for the 20 next hours')
    plt.xlabel('Time (one measure = two hours)')
    plt.ylabel('Humidity (%)')
    
    if prediction.any():
        plt.plot(np.arange(num_futur), np.array(prediction), 'ro', label='Predicted Futur ')
    plt.legend(loc='upper left')
    plt.show()

#Denormalize to have true values 
denorm_X_test = denormalize(np.array(X_test_hu[91]),meteo_test_not_norm,'hu')
denorm_Y_test = denormalize(np.array(Y_test_hu[91]),meteo_test_not_norm,'hu')
denorm_Y_pred = denormalize(np.array(YPred_hum[91]),meteo_test_not_norm,'hu')

plot_multi_etape_hu(denorm_X_test,denorm_Y_test, denorm_Y_pred)

"""#### Comments

The above graph is predicting the $20$ $next$ $hours$ of humidity. So the model can be used to check the humidity percentage **the evening before the expedition**.

Humidity : amount of water vapour in the air,100% humidity: the vapour forming droplets and 0% : no water vapour at all. 

**Humidity and temperature are correlated** but we will put simple threshold.

Example:
70% humidity / 20°C = good conditions.

70% humidity / 15°C = bad conditions.

**Our simple model:**

 Above 75%: too humid, too slippery. 

 Bellow 20%: too dry.

## For windspeed
"""

#normalize dataset

meteo = normalize(meteo_not_norm,'ff')
meteo_test = normalize(meteo_test_not_norm,'ff')

# we take the average on periods of 120 measures 
# transform to 12 periods of 2hours 
meteo_cp = meteo.resample('120T').mean()
meteo_test_cp = meteo_test.resample('120T').mean()

# We assume constant temperature if we don't have any information
meteo_cp = meteo_cp.fillna(method='bfill')
meteo_test_cp = meteo_test_cp.fillna(method='bfill')


X_entrainement_ff,Y_entrainement_ff=segmentation(meteo_cp)
X_test_ff,Y_test_ff=segmentation(meteo_test_cp)

modele_lstm_ff = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(point_hist, input_shape=X_entrainement_ff.shape[-2:]),
    tf.keras.layers.Dense(50),
    tf.keras.layers.Dense(50),
    tf.keras.layers.Dense(point_predis)
    ])

#Comple with mse 
modele_lstm_ff.compile(optimizer='adam', metrics=['mae'], loss='mse')

#train 
history_ff = modele_lstm_ff.fit(X_entrainement_ff, Y_entrainement_ff, epochs=EPOCH, verbose = 0)

#predict with the station test 
YPred_ff = modele_lstm_ff.predict(X_test_ff, verbose=0)

modele_lstm_ff.summary()

# Evaluate the model on training set:
score = modele_lstm_ff.evaluate(X_entrainement_ff, Y_entrainement_ff, verbose=0)
print(' Train loss:', score[0])


# Evaluate the model on validation set:
score = modele_lstm_ff.evaluate(X_test_ff, Y_test_ff, verbose=0)
print(' Test loss:', score[0])

import matplotlib.pyplot as plt
fig, ax = plt.subplots()
epoch = range(100)
ax.plot(epoch,history_ff.history['loss'],'o-',label="loss")
ax.set_xlabel("Epochs")
ax.set_ylabel("Cross_entropy loss")
ax.legend()
ax.set_title('Loss plot for epoch iteration')
plt.savefig("Loss_Train")

Y_test_ff = Y_test_ff.reshape(Y_test_ff.shape[0], point_predis)
#Lists that contains values of prediction 
final_list_ff = []
Val_list_ff = []

# Among all the points predicted we take only one 

###  Prediction Y_pred from X_test 
for preds in YPred_ff:
    final_list_ff.append(preds[1])
train_np_array_ff = np.array(final_list_ff)
meteo_test_not_norm = index(num_test_station)
train_val_ff = denormalize(train_np_array_ff, meteo_test_not_norm, 'ff')



### True Y_test from X_test (Y_true) 
for preds in Y_test_ff:
    Val_list_ff.append(preds[1])   
test_np_array_ff = np.array(Val_list_ff)
test_val_ff = denormalize(test_np_array_ff,meteo_test_not_norm,'ff')

plt.figure(figsize=(30,5))
sns.set(rc={"lines.linewidth": 3})
sns.lineplot(x=np.arange(train_val_ff[:300].shape[0]), y=train_val_ff[:300], color="green")
sns.set(rc={"lines.linewidth": 3})
sns.lineplot(x=np.arange(test_val_ff[:300].shape[0]), y=test_val_ff[:300], color="coral")
plt.margins(x=0, y=0.5)
plt.xlabel('Time')
plt.ylabel('Wind speed (m/s)')
plt.legend(["Original", "Prédiction"])

def plot_multi_etape_ff(historique, vrai_futur, prediction):
    plt.figure(figsize=(12, 6))
    num_passe = temp_int(len(historique))
    num_futur = len(vrai_futur)
    plt.plot(num_passe, np.array(historique[:, 0]), label='given passed')
    plt.plot(np.arange(num_futur), np.array(vrai_futur), label='True future')
    plt.fill_between(range(-70,10), 0, 14.5, color='C0', alpha = 0.3, label = "Good wind speed conditions")
    plt.title('Prediction of wind speed rate for the 20 next hours')
    plt.xlabel('Time (one measure = two hours)')
    plt.ylabel('Wind speed (m/s)')
    
    if prediction.any():
        plt.plot(np.arange(num_futur), np.array(prediction), 'ro', label='Predicted Futur ')
    plt.legend(loc='upper left')
    plt.show()



denorm_X_test = denormalize(np.array(X_test_ff),meteo_test_not_norm,'ff')
denorm_Y_test = denormalize(np.array(Y_test_ff),meteo_test_not_norm,'ff')
denorm_Y_pred = denormalize(np.array(YPred_ff),meteo_test_not_norm,'ff')
plot_multi_etape_ff(denorm_X_test[100],denorm_Y_test[100], denorm_Y_pred[100])

"""# For temperature """

#normalize dataset
meteo = normalize(meteo_not_norm,'t')
meteo_test = normalize(meteo_test_not_norm,'t')

# we take the average on periods of 120 measures 
# transform to 12 periods of 2hours 
meteo_cp = meteo.resample('120T').mean()
meteo_test_cp = meteo_test.resample('120T').mean()

# We assume constant temperature if we don't have any information
meteo_cp = meteo_cp.fillna(method='bfill')
meteo_test_cp = meteo_test_cp.fillna(method='bfill')

# For wind speed
X_entrainement_t,Y_entrainement_t=segmentation(meteo_cp)
X_test_t,Y_test_t=segmentation(meteo_test_cp)

modele_lstm_t = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(point_hist, input_shape=X_entrainement_t.shape[-2:]),
    tf.keras.layers.Dense(100),
    tf.keras.layers.Dense(50),
    tf.keras.layers.Dense(point_predis)
    ])

#Comple with mse 
modele_lstm_t.compile(optimizer='adam', metrics=['mae'], loss='mse')

#train 
history_t = modele_lstm_t.fit(X_entrainement_t, Y_entrainement_t, epochs=EPOCH)

#predict with the station test 
YPred_t = modele_lstm_t.predict(X_test_t, verbose=0)
Y_test_t = Y_test_t.reshape(Y_test_t.shape[0], point_predis,)

# Evaluate the model on training set:
score = modele_lstm_t.evaluate(X_entrainement_t, Y_entrainement_t, verbose=0)
print(' Train loss:', score[0])


# Evaluate the model on validation set:
score = modele_lstm_t.evaluate(X_test_t, Y_test_t, verbose=0)
print(' Test loss:', score[0])

import matplotlib.pyplot as plt
fig, ax = plt.subplots()
epoch = range(100)
ax.plot(epoch,history_t.history['loss'],'o-',label="loss")
ax.set_xlabel("Epochs")
ax.set_ylabel("Cross_entropy loss")
ax.legend()
ax.set_title('Loss plot for epoch iteration')
plt.savefig("Loss_Train")

#Lists that contains values of prediction 
final_list_t = []
Val_list_t = []

# Among all the points predicted we take only one 

###  Prediction Y_pred from X_test 
for preds in YPred_t:
    final_list_t.append(preds[1])
train_np_array_t = np.array(final_list_t)
meteo_test_not_norm = index(num_test_station)
train_val_t = denormalize(train_np_array_t, meteo_test_not_norm, 't')



### True Y_test from X_test (Y_true) 
for preds in Y_test_t:
    Val_list_t.append(preds[1])   
test_np_array_t = np.array(Val_list_t)
test_val_t = denormalize(test_np_array_t,meteo_test_not_norm,'t')

print(train_val_t.shape)
print(test_val_t.shape)

plt.figure(figsize=(30,5))
sns.set(rc={"lines.linewidth": 3})
sns.lineplot(x=np.arange(train_val_t[:300].shape[0]), y=train_val_t[:300], color="green")
sns.set(rc={"lines.linewidth": 3})
sns.lineplot(x=np.arange(test_val_t[:300].shape[0]), y=test_val_t[:300], color="coral")
plt.margins(x=0, y=0.5)
plt.xlabel('Time')
plt.ylabel('Temperature')
plt.legend(["Original", "Prédiction"])

def plot_multi_etape_t(historique, vrai_futur, prediction):
    plt.figure(figsize=(12, 6))
    num_passe = temp_int(len(historique))
    num_futur = len(vrai_futur)
    plt.plot(num_passe, np.array(historique[:, 0]), label='given passed')
    plt.plot(np.arange(num_futur), np.array(vrai_futur), label='True future')
    plt.fill_between(range(-70,10), 273, 300, color='C0', alpha = 0.3, label = "Good temperature conditions")
    plt.title('Prediction of temperature for the 20 next hours')
    plt.xlabel('Time (one measure = two hours)')
    plt.ylabel('Temperature (K)')
    
    if prediction.any():
        plt.plot(np.arange(num_futur), np.array(prediction), 'ro', label='Predicted Futur ')
    plt.legend(loc='upper left')
    plt.show()



denorm_X_test = denormalize(np.array(X_test_t),meteo_test_not_norm,'t')
denorm_Y_test = denormalize(np.array(Y_test_t),meteo_test_not_norm,'t')
denorm_Y_pred = denormalize(np.array(YPred_t),meteo_test_not_norm,'t')


plot_multi_etape_t(denorm_X_test[60],denorm_Y_test[60], denorm_Y_pred[60])

"""# Save models for app use"""

tf.saved_model.save(modele_lstm_hum, '/content/hum')
tf.saved_model.save(modele_lstm_ff, '/content/ff')
tf.saved_model.save(modele_lstm_t, '/content/t')

!zip -r /content/hum.zip /content/hum
!zip -r /content/ff.zip /content/ff
!zip -r /content/t.zip /content/t

from google.colab import files
files.download("/content/hum.zip")
files.download("/content/ff.zip")
files.download("/content/t.zip")