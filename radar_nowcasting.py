# -*- coding: utf-8 -*-
"""radar_nowcasting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wgcSnNN-2QexveGl6gcrplDuqaNji3F6
"""

!pip uninstall shapely
!pip install shapely --no-binary shapely

def create_dic_borne(N, S, W, E):
    dic = {
        'uly': N,
        'lry': S,
        'ulx': W,
        'lrx': E
    }
    return dic


DOMAINS = {
    'NW':  create_dic_borne(51.896, 46.25, -5.842, 2),
    'SE':  create_dic_borne(46.25, 41.1, 2, 9.842)
    }

"""Goal: use Radar dataset as an image and predict the movement of a rainmap radar using deep learning. 


Data info: one archive per month, each one sliced in periods of 10 or 11 days (each month separated in 3 files). 

In our test: forecast one hour data and use a 15 minuts steps. 
"""

# Install cartopy on google colab 
!apt-get -qq install python-cartopy python3-cartopy;

# IMPORT THE LIBRARIES
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras.optimizers import *
import cartopy.crs as ccrs
import cartopy.feature as cfeature
import matplotlib.pyplot as plt
from matplotlib import colors
from cartopy.mpl.geoaxes import GeoAxes
from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1 import AxesGrid
from matplotlib import colors
import cartopy.feature as cfeature

"""# Dataset """

from google.colab import drive
drive.mount('/content/drive/')

# Import a constant.py file on google colab
import sys
sys.path.insert(0,'/content/drive/MyDrive/project/')

"""#### Explore the dataset

On archive of year 2017 in zone 'South-East' separated to different folders per months. Each folder contains 3 .npz files (each months sliced in periods of 10 or 11 days).

Example slice in one month:

- part 1: from day 1 to 9
- part 2: from day 10 to 20
- part 3: from day 21 to day 30 or 31. 


Each .npz file contains 3 arrays :

data : an array containing maps of radar data values.

dates : an array containing a datetime object and indicating the date of each data map.

miss_dates : an array containing a datetime object for each missing radar map over the period.

The **time step between two radar scans is 5 min**. The radar starts scanning at 00h every day and ends at 23h55. So each file of 11 days should contain a maximum of 3168 rainfall maps (minus the missing dates).

The radar's spatial resolution is 0.01° and the projection system used is EPSG:4326.

You will also find a radar_coords_ZONE.npz file containing 2 arrays lats and lons, indicating the coordinates (latitude and longitude) of the center of each radar pixel.
"""

f_coords = '/content/drive/My Drive/project/data/radar/radar_coords_SE.npz'
fname = '/content/drive/My Drive/project/data/radar/rainfall-SE-2017-09/rainfall_SE_2017_09.1.npz'
coordinates = np.load(f_coords,allow_pickle=True)
d = np.load(fname, allow_pickle=True)
data = d['data']
dates = d['dates']
miss_dates = d['miss_dates']
lat = coordinates['lats']
lon = coordinates['lons']
zone = "SE"

print(data[0].shape)
miss_dates.shape
print(data.shape)
#print(data[0].shape)
#print(lat.shape)
#print(dates[0])

"""
Dimensions of the ```data``` array: 

* Number of records : the radar records a scan every 5 min

* Number of points on the y axis : latitude (515)

* Number of points on the x axis : longitude (784)

"""

title = "4 examples of rainfall plots"
fig, ax = plt.subplots(2, 2,figsize=(9,9))
fig.suptitle(title, fontsize=16)

month = 5
part_month = 3
# Choose the colormap
cmap = colors.ListedColormap(['silver','white', 'darkslateblue', 'mediumblue','dodgerblue', 
                              'skyblue','olive','mediumseagreen','cyan','lime','yellow',
                              'khaki','burlywood','orange','brown','pink','red','plum'])
bounds = [-1,0,2,4,6,8,10,15,20,25,30,35,40,45,50,55,60,65,75]
norm = colors.BoundaryNorm(bounds, cmap.N)

pl=ax[0,0].pcolormesh(lon, lat, data[0,:,:],cmap=cmap, norm=norm)
ax[0,0].set_ylabel('latitude (degrees_north)')
ax[0,0].set_title(str(dates[0]) + " - "+  zone + " zone")

pl=ax[0,1].pcolormesh(lon, lat, data[1,:,:],cmap=cmap, norm=norm)
ax[0,1].set_title(str(dates[1]) + " - "+  zone + " zone")

pl=ax[1,0].pcolormesh(lon, lat, data[2,:,:],cmap=cmap, norm=norm)
ax[1,0].set_xlabel('longitude (degrees_east)')
ax[1,0].set_ylabel('latitude (degrees_north)')
ax[1,0].set_title(str(dates[2]) + " - "+  zone + " zone")

pl=ax[1,1].pcolormesh(lon, lat, data[3,:,:],cmap=cmap, norm=norm)
ax[1,1].set_xlabel('longitude (degrees_east)')
ax[1,1].set_title(str(dates[3]) + " - "+  zone + " zone")

# Plot the color bar
cbar = fig.colorbar(pl,ax=ax.ravel().tolist(),cmap=cmap, norm=norm, boundaries=bounds, ticks=bounds, 
                orientation= 'vertical').set_label('Rainfall (in 1/100 mm) / -1 : missing values')
plt.show()

#coordinates of study zone boundaries
lllat=DOMAINS[zone]['lry']    #lower left latitude
urlat=DOMAINS[zone]['uly']    #upper right latitude
lllon=DOMAINS[zone]['ulx']    #lower left longitude
urlon=DOMAINS[zone]['lrx']    #upper right longitude
extent = [lllon, urlon, lllat, urlat]

fig = plt.figure(figsize=(9,10))

# Select projection
ax = plt.axes(projection=ccrs.PlateCarree())

# Plot the data
plt.imshow(data[0], interpolation='none', origin='upper',cmap=cmap, norm=norm, extent=extent)

# Add coastlines and borders
#ax.coastlines(resolution='50m', linewidth=1)
#ax.add_feature(cfeature.BORDERS.with_scale('50m'))

ax.coastlines( linewidth=1)
ax.add_feature(cfeature.BORDERS)
# Show only the area we defined
ax.set_extent(extent)

# Add the colorbar
plt.colorbar(cmap=cmap, norm=norm, boundaries=bounds, ticks=bounds, 
             orientation= 'horizontal').set_label('Rainfall (in 1/100 mm) / -1 : missing values')
plt.title("Rainfalls - "+ str(dates[0]) + " - "+  zone + " zone")
plt.show()

def load_fichier(part_month,month):
    directory = '/content/drive/My Drive/project/data/radar/'
    #fname = directory + 'rainfall_{zone}_{str(year)}_{str(month).zfill(2)}.{str(part_month)}.npz'
    fname = directory + f'rainfall-SE-2017-{str(month).zfill(2)}/rainfall_SE_2017_{str(month).zfill(2)}.{str(part_month)}.npz'
    pickle = np.load(fname, allow_pickle=True)
    coords_path = '/content/drive/My Drive/project/data/radar/radar_coords_SE.npz'
    coordinates = np.load(coords_path,allow_pickle=True)
    lat = coordinates['lats']
    lon = coordinates['lons']
    #print('shape lat',np.shape(lat))
    #print('shape lon', np.shape(lon))
    return pickle, lat, lon

"""# Usefull function """

# Convert the given date of the pickle to the missing index.
def indice_miss_date(pickle):
    indice_tab= np.zeros(pickle['miss_dates'].shape[0],dtype=int)
    print("This is the missing date in the data: ",pickle['miss_dates'])
    for miss_date in pickle['miss_dates']:
        print(miss_date)
        compteur=0
        Diff_year = miss_date.year - pickle['dates'][0].year
        Diff_Month = miss_date.month - pickle['dates'][0].month
        Diff_Day = miss_date.day - pickle['dates'][0].day
        Diff_Hour = miss_date.hour - pickle['dates'][0].hour
        Diff_Minute = miss_date.minute - pickle['dates'][0].minute

        indice = Diff_Day*24*12 + Diff_Hour*12 + Diff_Minute/5

        indice_abs= int(indice) / indice
        # We raise error because for now we don't handle that kind of situation
        if Diff_year != 0 or Diff_Month != 0:
            raise NameError('There is a difference in month or year !')
        if indice_abs != 1:
            raise NameError('Indice is not a integer')
        else:
            indice_tab[compteur]= int(indice)
        compteur+=1
    return indice_tab


# cut the input data by the step we have consider
# if step_minute = 15: we take every 3 points (step = 3)
def cut_timestep(pickle,Step_minute):
    Step_data = 5
    Step = Step_minute // Step_data
    print("We make a step every ",Step,"indices")
    Val_selec=np.arange(0,len(pickle['dates']),Step) # Every 15 minuts
    return pickle['data'][Val_selec,:,:],pickle['dates'][Val_selec]


# If Missing values.
def cut_timestep_miss(pickle, Echeance_minute, Step_minute) :
    Step_data = 5
    Step = Step_minute // Step_data
    Entrainement = Echeance_minute//15 + 1
    Prediction = Echeance_minute//15
    Tot = Entrainement + Prediction
    Qinit = (Step * Tot) - Step
    Q1= Step * Tot
  #  print('là',Q1)
    indice_tab= indice_miss_date(pickle) # LOAD indice_miss_date function to get the missing indices 
    Tab_index=[]
    
    valeur_init=0
    for indice in indice_tab:
        Quotient= indice // Q1
        Reste = indice % Q1
        if Quotient > 1:
            Index_end = Qinit + (Quotient - 1) * Q1
            New_begin_index = Index_end + Q1 + Step - 1
        elif Quotient == 1:
            Index_end = Qinit * Quotient
            New_begin_index = Index_end + Q1 + Step - 1
        else :
            Index_end = Qinit * Quotient
            New_begin_index = Index_end + Q1 - 1
        Sequence = np.arange(valeur_init , Index_end+1 , 3 , dtype=int)
        Tab_index.append(Sequence[:])
        valeur_init = New_begin_index
     #   print(indice,Quotient,Reste,Index_end,Sequence,New_begin_index,Tab_index,valeur_init)
    Sequence = np.arange(valeur_init ,pickle["dates"].shape[0] , 3 , dtype=int)
    Tab_index.append(Sequence[:])
    return Tab_index

def cut_data_and_coord(data,Pixel,lat,lon,lat_edge=49.5,lon_edge=5):
    lat_only=lat[:,1]
    lon_only=lon[1,:]
    Temp_lat = np.where(lat_only < lat_edge)
    Temp_lon = np.where(lon_only < lon_edge)
    Lat_cut_index = Temp_lat[0][:Pixel]
    Lon_cut_index = Temp_lon[0][:Pixel]
    data_cut = data[:,Lat_cut_index]
    data_cut= data_cut[:,:,Lon_cut_index]
    return data_cut

def cut_timestep_miss2(pickle,Echeance_minute,Step_minute):
    Tab = cut_timestep_miss(pickle,Echeance_minute,Step_minute)
    shape = len(Tab)
    Tab_tot = np.empty(0,dtype=int)
    for i in range(shape):
        Tab_tot=np.concatenate((Tab_tot,Tab[i]))
        
    return pickle['data'][Tab_tot,:,:],pickle['dates'][Tab_tot]

# CODE TO CHANGE DATA BY 1 OR 0
def data_threshold(data_cut,rain_limit):
    data_cut[data_cut > rain_limit ] = 1
    data_cut[data_cut <= rain_limit ] = 0
    return data_cut

def XYTRAIN(data_process):
    X_Train=np.zeros((0,256,256,5))
    Y_Train=np.zeros((0,256,256,4))
    #X_Train=np.zeros((0,256,50,5))
    #Y_Train=np.zeros((0,256,50,4))
    DATA_X=np.zeros((1,256,256,5))
    DATA_Y=np.zeros((1,256,256,4))
    #DATA_X=np.zeros((1,256,50,5))
    #DATA_Y=np.zeros((1,256,50,4))
    step_X=0
    step_Y=4
    print("We want ",int(data_process.shape[0]/9), "frames" )
    for globale in range(int(data_process.shape[0]/9)):
        for X in range(1,6):
            DATA_X[0,:,:,X-1]=data_process[step_X+X-1,:,:]
        for Y in range(1,5):
            DATA_Y[0,:,:,Y-1]=data_process[step_Y+Y,:,:]
        step_X+=9
        step_Y+=9
        X_Train= np.append(X_Train,DATA_X,axis=0)
        Y_Train= np.append(Y_Train,DATA_Y,axis=0)
        DATA_X=np.zeros((1,256,256,5)) # each package in X_train are 5 frames selected thanks to a step
        DATA_Y=np.zeros((1,256,256,4))
    return X_Train,Y_Train

def COUNT_RAIN_SITUATION(X_TRAIN,Y_TRAIN):
    Count_X=0
    Count_Y=0
    Tab_delete=[]
    Count=0
    for X in X_TRAIN:
        #print(X)
        # count the number of non null values 
        Temp_x = np.count_nonzero(X == 1)
        if (Temp_x <= 200):
            Count_X += 1
            Tab_delete.append(Count)
        Count +=1
    for Y in Y_TRAIN:
        Temp_y = np.count_nonzero(Y == 1)
        if Temp_y <= 200:
            Count_Y += 1
            
    X_TRAIN = np.delete(X_TRAIN,Tab_delete,axis=0)
    Y_TRAIN = np.delete(Y_TRAIN,Tab_delete,axis=0)
        
    return(X_TRAIN,Y_TRAIN,Count_X,Count_Y)

# CONFIGURATION DATA
# CHOOSE THE STEP AND THE ECHEANCE
Echeance_minute = 60
Step_minute = 15
Pixel=256
rain_limit = 0

## For train data 
month=[1,2]
part=[1,2]

## LOOP FOR TRAIN DATA
init=0
for m in month:
    for p in part:
        pickle, lat, lon = load_fichier(p,m)
        print("This is the part " ,p)
        if pickle["miss_dates"].shape[0] == 0:
            print("There is no missing data in this chunk")
            # Steps of 15 minutes: 
            data_radar,dates_radar = cut_timestep(pickle,Step_minute)
            print( 'shape after cut timestep', data_radar.shape)
            # We take the part of the data we are interested in:
            data_cut = cut_data_and_coord(data_radar,Pixel,lat,lon)
            print('after cut data', data_cut.shape)  
            # We use the rain threshold (rain limit at 0)    
            data_process = data_threshold(data_cut,rain_limit)
            print('after threshold data', data_process.shape)  
            print("Data have been threshold")
            X_TRAIN,Y_TRAIN = XYTRAIN(data_process)
            print("Shape of the temporary train data",X_TRAIN.shape,Y_TRAIN.shape)
        else:
            print("There is miss dates")
            data_radar,dates_radar = cut_timestep_miss2(pickle,Echeance_minute,Step_minute)
            print(data_radar.shape)
            data_cut = cut_data_and_coord(data_radar,Pixel,lat,lon)
            print( data_cut.shape)
            data_process = data_threshold(data_cut,rain_limit)
            print("Data have been threshold")
            X_TRAIN,Y_TRAIN = XYTRAIN(data_process)
            print("Shape of the temporary train data",X_TRAIN.shape,Y_TRAIN.shape)
        
        if (init == 0):
            X_TEMP=X_TRAIN
            Y_TEMP=Y_TRAIN
            print("STEP N°1: ",X_TEMP.shape,Y_TEMP.shape)
        elif ( init == 1):
            X_train= np.append(X_TEMP,X_TRAIN,axis=0)
            Y_train= np.append(Y_TEMP,Y_TRAIN,axis=0)
            print("STEP N°2: ",X_train.shape,Y_train.shape)
        else:
            X_train= np.append(X_train,X_TRAIN,axis=0)
            Y_train= np.append(Y_train,Y_TRAIN,axis=0)
            print("OTHER STEP : ",X_train.shape,Y_train.shape)
        init += 1
        print("----------------------------------------------------------------------")

#Let some place in the memory  
del(X_TEMP,Y_TEMP,X_TRAIN,Y_TRAIN,data_cut,data_radar,data_process)

# SHOW THE SITUATION WITHOUT METEO DATA
print(X_train.shape,Y_train.shape)
X_train,Y_train,Count_X,Count_Y = COUNT_RAIN_SITUATION(X_train,Y_train)
print(X_train.shape,Y_train.shape,Count_X,Count_Y)

"""# CONVOLUTIONAL NEURAL NETWORK

From the paper:
["Distributed Deep Learning for Precipitation
Nowcasting"](https://arxiv.org/pdf/1908.10964.pdf)


The neural network we use has a **U-NET** architecture. It has an encoder/decoder architecture.

**Encoding phase :**
Input of size $25*6256*5$ representing 5 frames (15 minutes step), processesed by Convolutional Layers. Each strided convolution effectively generates feature maps of lower resolutions.

**Decoding phase :**
each layer is upsampled to twice the size, and followed by another
convolution.


In the final
output, three additional convolutions are applied to generate
the final output at the initial resolution.

CNN architecture: fully coonvolutional(no dense layers)


Loss function = MSE between the predicted VIL estimates and truth downsampled to the necessary resolution. 
"""

#Input 
inputs = keras.Input(shape=(256,256,5))


# Encoder 
conv1 = layers.Conv2D(filters=32,kernel_size=(3,3),activation="relu", padding="same")(inputs)
conv1 = layers.Conv2D(filters=32,kernel_size=(3,3),activation="relu", padding="same")(conv1)

maxpool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)

conv2 = layers.Conv2D(filters=64,kernel_size=(3,3),activation="relu", padding="same")(maxpool1)
conv2 = layers.Conv2D(filters=64,kernel_size=(3,3),activation="relu", padding="same")(conv2)

maxpool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)


conv3 = layers.Conv2D(filters=128,kernel_size=(3,3),activation="relu", padding="same")(maxpool2)
conv3 = layers.Conv2D(filters=128,kernel_size=(3,3),activation="relu", padding="same")(conv3)

maxpool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)

conv4 = layers.Conv2D(filters=256,kernel_size=(3,3),activation="relu", padding="same")(maxpool3)
conv4 = layers.Conv2D(filters=256,kernel_size=(3,3),activation="relu", padding="same")(conv4)
drop4 = layers.Dropout(0.5)(conv4)

maxpool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)

conv5 = layers.Conv2D(filters=512,kernel_size=(3,3),activation="relu", padding="same")(maxpool4)
conv5 = layers.Conv2D(filters=512,kernel_size=(3,3),activation="relu", padding="same")(conv5)
drop5 = layers.Dropout(0.5)(conv5)


# Decoder 
up6 = layers.Conv2D(256, 2, activation = 'relu', padding="same")(layers.UpSampling2D(size = (2,2))(drop5))
merge6 = layers.concatenate([drop4,up6], axis = 3)

conv6 = layers.Conv2D(256, 3, activation = 'relu', padding="same")(merge6)
conv6 = layers.Conv2D(256, 3, activation = 'relu', padding="same")(conv6)



up7 = layers.Conv2D(128, 2, activation = 'relu', padding="same")(layers.UpSampling2D(size = (2,2))(conv6))
merge7 = layers.concatenate([conv3,up7], axis = 3)
conv7 = layers.Conv2D(128, 3, activation = 'relu', padding="same")(merge7)
conv7 = layers.Conv2D(128, 3, activation = 'relu', padding="same")(conv7)



up8 = layers.Conv2D(64, 2, activation = 'relu', padding="same")(layers.UpSampling2D(size = (2,2))(conv7))
merge8 = layers.concatenate([conv2,up8], axis = 3)
conv8 = layers.Conv2D(64, 3, activation = 'relu', padding="same")(merge8)
conv8 = layers.Conv2D(64, 3, activation = 'relu', padding="same")(conv8)

up9 = layers.Conv2D(32, 2, activation = 'relu', padding="same")(layers.UpSampling2D(size = (2,2))(conv8))
merge9 = layers.concatenate([conv1,up9], axis = 3)
conv9 = layers.Conv2D(32, 3, activation = 'relu', padding="same")(merge9)
conv9 = layers.Conv2D(32, 3, activation = 'relu' , padding="same")(conv9)
conv10 = layers.Conv2D(4, 3, activation = 'sigmoid', padding="same")(conv9)


model= keras.Model(inputs,conv10)
model.compile(optimizer = "Adam", loss = 'binary_crossentropy', metrics = ['binary_accuracy'])
model.summary()

history=model.fit(X_train,Y_train,batch_size=32, epochs=10, verbose = 0)



# MAKE PLACE IN MEMORY
del(X_train,Y_train)

"""# Plot the results"""

import matplotlib.pyplot as plt
fig, ax = plt.subplots()
epoch = range(10)
ax.plot(epoch,history.history['loss'],'o-',label="loss")
ax.set_xlabel("Epochs")
ax.set_ylabel("Cross_entropy loss")
ax.legend()
ax.set_title('Loss plot for epoch iteration')
plt.savefig("Loss_Train")

fig, ax = plt.subplots()
ax.plot(epoch,history.history['binary_accuracy'],'o-',label="accuracy")
ax.set_xlabel("Epochs")
ax.set_ylabel("Accuracy metrics")
ax.legend()
ax.set_title('Accuracy plot for epoch iteration')
plt.savefig("Accuracy_Train")

"""# Test data 

"""

# For test data 
month = [4]
part_test = [1,2]

## LOOP FOR TEST DATA
# LOOP FOR TRAIN DATA
init=0
for m in month:
    for p in part:
        pickle, lat, lon = load_fichier(p,m)
        print("This is the part " ,p)
        if pickle["miss_dates"].shape[0] == 0:
            print("There is no missing data in this chunk")
            data_radar,dates_radar = cut_timestep(pickle,Step_minute)
            print( 'shape after cut timestep', data_radar.shape)
            data_cut = cut_data_and_coord(data_radar,Pixel,lat,lon)
            print('after cut data', data_cut.shape)       
            data_process = data_threshold(data_cut,rain_limit)
            print('after threshold data', data_process.shape)  
            print("Data have been threshold")
            X_TEST,Y_TEST = XYTRAIN(data_process)
            print("Shape of the temporary test data",X_TEST.shape,Y_TEST.shape)
        
        else:
            print("There is miss dates")
            data_radar,dates_radar = cut_timestep_miss2(pickle,Echeance_minute,Step_minute)
            print(data_radar.shape)
            data_cut = cut_data_and_coord(data_radar,Pixel,lat,lon)
            print( data_cut.shape)
            data_process = data_threshold(data_cut,rain_limit)
            print("Data have been threshold")
            X_TEST,Y_TEST = XYTRAIN(data_process)
            print("Shape of the temporary train data",X_TEST.shape,Y_TEST.shape)
        
        if (init == 0):
            X_TEMP=X_TEST
            Y_TEMP=Y_TEST
            print("STEP N°1: ",X_TEMP.shape,Y_TEMP.shape)
        elif ( init == 1):
            X_test= np.append(X_TEMP,X_TEST,axis=0)
            Y_test= np.append(Y_TEMP,Y_TEST,axis=0)
            print("STEP N°2: ",X_test.shape,Y_test.shape)
        else:
            X_test= np.append(X_test,X_TEST,axis=0)
            Y_test = np.append(Y_test,Y_TEST,axis=0)
            print("OTHER STEP : ",X_test.shape,Y_test.shape)
        init += 1
        print("----------------------------------------------------------------------")
    
#del(X_TEST,Y_TEST,data_cut,data_radar,data_process)

"""# Model evaluation """

# EVALUATE THE MODEL ON TEST DATA.
print("Evaluate on test data")
results = model.evaluate(X_test, Y_test, batch_size=20)
# EVALUATE THE MODEL WITH THAT
print("test loss, test acc:", results)
Y_predict = model.predict(X_test)
#Y_predict.shape

from sklearn.metrics import log_loss
#accuracy = accuracy_score(Y_predict,Y_test)
log_loss= log_loss(np.ravel(Y_test[:,:,:,3]), np.ravel(Y_predict[:,:,:,3]))
print(log_loss)

print(log_loss)
log_loss_tab= [None,0.15,0.2,0.24,0.26]

#del(X_test,Y_test)
#del(model)

def LATLON_CUT(lat,lon):
    lat_edge=49.5
    lon_edge=5
    lat_only=lat[:,1]
    lon_only=lon[1,:]
    Temp_lat = np.where(lat_only < lat_edge)
    Temp_lon = np.where(lon_only < lon_edge)
    Lat_cut_index = Temp_lat[0][:Pixel]
    Lon_cut_index = Temp_lon[0][:Pixel]
    lat_format= lat[Lat_cut_index,Lon_cut_index]
    lon_format= lon[Lat_cut_index,Lon_cut_index]
    return lat_format,lon_format

# Lat/Lon formating for plot.
lat_format,lon_format = LATLON_CUT(lat,lon)

lllat = lat_format[-1]  #lower left latitude
urlat = lat_format[0]  #upper right latitude
lllon =  lon_format[0]  #lower left longitude
urlon =lon_format[-1]  #upper right longitude
extent = [lllon, urlon, lllat, urlat]
cmap = colors.ListedColormap(['silver','#85F599','blue','#FFFF57','#FFC400','#FF2200'])
cmap = colors.ListedColormap(['white', 'darkslateblue', 
                              'skyblue','cyan','lime','yellow',
                              'orange','brown','red','plum'])
bounds = [0,0.4,0.5,0.55,0.6,0.65,0.7,0.8,0.9,1]
norm = colors.BoundaryNorm(bounds, cmap.N)


lats,lons = np.meshgrid(lat_format,lon_format)

projection = ccrs.PlateCarree()
axes_class = (GeoAxes,dict(map_projection=projection))

fig=plt.figure(figsize=(80,80))
axgr= AxesGrid(fig, 222, axes_class=axes_class,
                    nrows_ncols=(2, 9),
                    axes_pad=0.2,
                    cbar_location='right',
                    cbar_mode= 'single',
                    cbar_size='5%',
                    label_mode='')
                   # shared_all=True)  # note the empty label_mode
Pas= 3
for i, ax in enumerate(axgr):
    ax.coastlines(resolution='50m', linewidth=2)
    if i < 5:
        p = ax.imshow(X_test[Pas,:,:,i],cmap=cmap,norm=norm, interpolation='none', origin='upper',extent=extent)
    elif i >= 5 and i < 9:
        p = ax.imshow(Y_test[Pas,:,:,i-5],cmap=cmap,norm=norm, interpolation='none', origin='upper',extent=extent)
    elif i >=9 and i < 14:
        p=  ax.imshow(X_test[Pas,:,:,i-9],cmap=cmap, interpolation='none', origin='upper',extent=extent)
    elif i >=14 and i < 19:
        p=  ax.imshow(Y_predict[Pas,:,:,i-14],cmap=cmap, interpolation='none', origin='upper',extent=extent)
axgr.cbar_axes[0].colorbar(p)
plt.show()
fig.savefig("Echeance 3")

"""# PLOTS 

"""

fig = plt.figure(figsize=(9,10))

# Select projection
ax = plt.axes(projection=ccrs.PlateCarree())

# Plot the data
plt.imshow(data[0], interpolation='none', origin='upper',cmap=cmap, norm=norm, extent=extent)

# Add coastlines and borders
#ax.coastlines(resolution='50m', linewidth=1)
#ax.add_feature(cfeature.BORDERS.with_scale('50m'))

ax.coastlines( linewidth=1)
ax.add_feature(cfeature.BORDERS)
# Show only the area we defined
ax.set_extent(extent)

# Add the colorbar
plt.colorbar(cmap=cmap, norm=norm, boundaries=bounds, ticks=bounds, 
             orientation= 'horizontal').set_label('Rainfall (in 1/100 mm) / -1 : missing values')
plt.title("Rainfalls - "+ str(dates[0]) + " - "+  zone + " zone")
plt.show()

"""# Save models for app use"""

tf.saved_model.save(model, '/content/model')

!zip -r /content/model.zip /content/model

from google.colab import files
files.download("/content/model.zip")